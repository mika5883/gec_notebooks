{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7af1083-91d6-4103-9567-3131d68fdb3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T13:10:40.009089Z",
     "iopub.status.busy": "2025-04-02T13:10:40.008010Z",
     "iopub.status.idle": "2025-04-02T13:10:44.761419Z",
     "shell.execute_reply": "2025-04-02T13:10:44.760716Z",
     "shell.execute_reply.started": "2025-04-02T13:10:40.009048Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %pip -q install datasets\n",
    "# %pip -q install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f731558d-0760-42af-935c-b5b8187d8c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:06:39.796353Z",
     "iopub.status.busy": "2025-04-20T18:06:39.795411Z",
     "iopub.status.idle": "2025-04-20T18:06:49.852777Z",
     "shell.execute_reply": "2025-04-20T18:06:49.851816Z",
     "shell.execute_reply.started": "2025-04-20T18:06:39.796326Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e1601-73e9-4c88-8006-d555646840e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:06:49.854473Z",
     "iopub.status.busy": "2025-04-20T18:06:49.854Z",
     "iopub.status.idle": "2025-04-20T18:07:35.875029Z",
     "shell.execute_reply": "2025-04-20T18:07:35.874156Z",
     "shell.execute_reply.started": "2025-04-20T18:06:49.854453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-04-20 18:07:01.521332: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-20 18:07:11.122414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a631ba06-d47f-4658-a32f-16ddba28667c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:07:35.876590Z",
     "iopub.status.busy": "2025-04-20T18:07:35.875981Z",
     "iopub.status.idle": "2025-04-20T18:07:36.060926Z",
     "shell.execute_reply": "2025-04-20T18:07:36.059985Z",
     "shell.execute_reply.started": "2025-04-20T18:07:35.876569Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = '/home/jupyter/datasphere/project/rugec/data/RULEC-GEC.test.tsv'\n",
    "rulec_test = pd.read_csv(test, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e0fc65-1a35-4484-b09a-7d8c845c8b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:07:36.062726Z",
     "iopub.status.busy": "2025-04-20T18:07:36.062394Z",
     "iopub.status.idle": "2025-04-20T18:07:36.143079Z",
     "shell.execute_reply": "2025-04-20T18:07:36.142061Z",
     "shell.execute_reply.started": "2025-04-20T18:07:36.062706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "test_ds = Dataset.from_dict({'corrupt_sent':rulec_test['corrupt_sent'],'correct_sent' : rulec_test['correct_sent']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae8624c-bbb8-4819-bc62-ed0369281115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:07:36.144099Z",
     "iopub.status.busy": "2025-04-20T18:07:36.143787Z",
     "iopub.status.idle": "2025-04-20T18:07:36.164764Z",
     "shell.execute_reply": "2025-04-20T18:07:36.163782Z",
     "shell.execute_reply.started": "2025-04-20T18:07:36.144079Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corrupt_sent': 'Экологическая составляющая ситуации Аральского моря является в несколько видов .', 'correct_sent': 'Экологическая составляющая ситуации Аральского моря проявляется в нескольких аспектах .'}\n"
     ]
    }
   ],
   "source": [
    "for i in test_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2de558-81a9-4996-bb39-64f89d807bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:46:43.122570Z",
     "iopub.status.busy": "2025-04-20T18:46:43.122127Z",
     "iopub.status.idle": "2025-04-20T18:46:52.210527Z",
     "shell.execute_reply": "2025-04-20T18:46:52.209717Z",
     "shell.execute_reply.started": "2025-04-20T18:46:43.122541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'mika5883/pretrain_rugec_msu' #prefix = 'grammar: '\n",
    "model_name = 'mika5883/finetune_rugec_msu' #prefix = 'grammar: '\n",
    "# name = 'Askinkaty/RuT5_GEC' #prefix = 'improve_grammar: ' or 'improve_grammar'\n",
    "# model_name = 'mika5883/gan_gec'\n",
    "# model_name = 'mika5883/MT5_large_A_art'\n",
    "# name = 'mika5883/finetune_rugec_msu'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970e6b7-3fa3-46eb-86bd-9309f9cddf5b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-20T18:46:36.694185Z",
     "iopub.status.idle": "2025-04-20T18:46:36.694465Z",
     "shell.execute_reply": "2025-04-20T18:46:36.694352Z",
     "shell.execute_reply.started": "2025-04-20T18:46:36.694337Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples, prefix='grammar: '):\n",
    "    # inputs = [f'grammar: {each}' for each in examples['corrupt_sent']]\n",
    "    inputs = [f'{prefix}{each}' for each in examples]\n",
    "    # inputs = [each for each in examples['corrupt_sent']]\n",
    "    # targets = [each for each in examples['correct_sent']]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=128, padding='longest', truncation=True, return_tensors='pt')\n",
    "    # labels = tokenizer(text_target=targets, max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    # labels[\"input_ids\"] = [\n",
    "    #             [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    #         ] #замена токенов паддинга на -100, чтобы они не учитывались при подсчёте потерь\n",
    "    # model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs['inputs'] = inputs\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2e36a8c-b6df-4df9-ab18-55e12e431548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:42:54.659694Z",
     "iopub.status.busy": "2025-04-20T18:42:54.659382Z",
     "iopub.status.idle": "2025-04-20T18:42:54.669713Z",
     "shell.execute_reply": "2025-04-20T18:42:54.669077Z",
     "shell.execute_reply.started": "2025-04-20T18:42:54.659676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27a2df14-fd7c-4165-ac04-e990299bf07c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:46:58.093324Z",
     "iopub.status.busy": "2025-04-20T18:46:58.092865Z",
     "iopub.status.idle": "2025-04-20T18:46:58.107399Z",
     "shell.execute_reply": "2025-04-20T18:46:58.106574Z",
     "shell.execute_reply.started": "2025-04-20T18:46:58.093290Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs, maybe_arg=2):\n",
    "        if isinstance(inputs, str):\n",
    "            inputs = [inputs]\n",
    "        model_inputs = tokenize_function(inputs).input_ids.to(self.device)\n",
    "        return {\"inputs\": model_inputs}\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **model_inputs, \n",
    "                max_new_tokens=128, \n",
    "                num_return_sequences=7, \n",
    "                num_beams=7\n",
    "            )\n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        return tokenizer.batch_decode(\n",
    "            model_outputs, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.postprocess(self._forward(self.preprocess(inputs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92873ace-f93c-4521-9fd4-47d8b9c36393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:46:58.311809Z",
     "iopub.status.busy": "2025-04-20T18:46:58.311481Z",
     "iopub.status.idle": "2025-04-20T18:46:58.885167Z",
     "shell.execute_reply": "2025-04-20T18:46:58.884397Z",
     "shell.execute_reply.started": "2025-04-20T18:46:58.311791Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "gram = MyPipeline(model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45fc8a23-e6c4-4fe4-a624-b1b681fd4397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T16:54:26.592479Z",
     "iopub.status.busy": "2025-04-06T16:54:26.590657Z",
     "iopub.status.idle": "2025-04-06T16:54:26.620799Z",
     "shell.execute_reply": "2025-04-06T16:54:26.619540Z",
     "shell.execute_reply.started": "2025-04-06T16:54:26.592420Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrected_sents = []\n",
    "def div(outs=None, num_return_seqs:int=7) -> list[list[str]]:\n",
    "    return [outs[i:i+num_return_seqs] for i in range(0, len(outs), num_return_seqs)]\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60846a96-3fd8-4e6f-b7be-cab3dea5e3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:47:00.862499Z",
     "iopub.status.busy": "2025-04-20T18:47:00.862114Z",
     "iopub.status.idle": "2025-04-20T19:03:29.429796Z",
     "shell.execute_reply": "2025-04-20T19:03:29.428868Z",
     "shell.execute_reply.started": "2025-04-20T18:47:00.862479Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting: 100%|██████████| 79/79 [16:28<00:00, 12.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "corrected_sents = []\n",
    "batch_size = 64\n",
    "total_count = len(test_ds)\n",
    "chunks = ceil(total_count / batch_size)\n",
    "\n",
    "def div(outs, n=7):\n",
    "    return [outs[i:i+n] for i in range(0, len(outs), n)]\n",
    "\n",
    "for i in tqdm.tqdm(range(chunks), desc=\"Correcting\"):\n",
    "    batch = KeyDataset(test_ds, 'corrupt_sent')[i*batch_size:(i+1)*batch_size]\n",
    "    outputs = gram(batch)\n",
    "    corrected_sents.append(div(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32bd2dff-6de9-4ef3-8d58-711f2fb88ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:04:56.335452Z",
     "iopub.status.busy": "2025-04-20T19:04:56.334227Z",
     "iopub.status.idle": "2025-04-20T19:04:56.358969Z",
     "shell.execute_reply": "2025-04-20T19:04:56.358261Z",
     "shell.execute_reply.started": "2025-04-20T19:04:56.335429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "909b2733-9e53-46ef-ba8d-0dff53267e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T17:47:16.624739Z",
     "iopub.status.busy": "2025-04-06T17:47:16.623879Z",
     "iopub.status.idle": "2025-04-06T17:47:16.641038Z",
     "shell.execute_reply": "2025-04-06T17:47:16.639737Z",
     "shell.execute_reply.started": "2025-04-06T17:47:16.624703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "076e47a5-db1e-4242-9f31-b071289a48c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:04:59.300907Z",
     "iopub.status.busy": "2025-04-20T19:04:59.300461Z",
     "iopub.status.idle": "2025-04-20T19:04:59.356582Z",
     "shell.execute_reply": "2025-04-20T19:04:59.355884Z",
     "shell.execute_reply.started": "2025-04-20T19:04:59.300886Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cors = [b for a in corrected_sents for b in a]\n",
    "len(cors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ada85501-3985-4620-abff-263e14efaa74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:05:18.518384Z",
     "iopub.status.busy": "2025-04-20T19:05:18.517917Z",
     "iopub.status.idle": "2025-04-20T19:05:18.824616Z",
     "shell.execute_reply": "2025-04-20T19:05:18.823844Z",
     "shell.execute_reply.started": "2025-04-20T19:05:18.518363Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Экологическая составляющая ситуации Аральского моря является в несколько видов .',\n",
       " ['Экологическая составляющая ситуации Аральского моря является в несколько видов .',\n",
       "  'Экологическая составляющая ситуации Аральского моря является несколько видов .',\n",
       "  'Экологическая составляющая ситуации Аральского моря является всего несколько видов .',\n",
       "  'Экологическая составляющая ситуации у Аральского моря является в несколько видов .',\n",
       "  'Экологическая составляющая ситуации в Аральского моря является в несколько видов .',\n",
       "  'Экологическая составляющая ситуации в Аральского моря является несколько видов .',\n",
       "  'Экологическая составляющая ситуации у Аральского моря является несколько видов .'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_corrected_pairs = [each for each in zip(KeyDataset(test_ds, 'corrupt_sent'), cors)]\n",
    "# corrupt_corrected_pairs = [[each[0], each[1]] for each in corrupt_corrected_pairs]\n",
    "corrupt_corrected_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57bd6c53-a117-4431-9f44-f9e1f0c4ab1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T17:49:02.394484Z",
     "iopub.status.busy": "2025-04-06T17:49:02.393073Z",
     "iopub.status.idle": "2025-04-06T17:49:02.430045Z",
     "shell.execute_reply": "2025-04-06T17:49:02.428986Z",
     "shell.execute_reply.started": "2025-04-06T17:49:02.394427Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Экологическая составляющая ситуации Аральского моря проявляется в нескольких аспектах .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rulec_test.iloc[0]['correct_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3d463e6-667f-4f9f-bfc7-2545c33c959f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:05:09.859754Z",
     "iopub.status.busy": "2025-04-20T19:05:09.859299Z",
     "iopub.status.idle": "2025-04-20T19:05:09.877957Z",
     "shell.execute_reply": "2025-04-20T19:05:09.877169Z",
     "shell.execute_reply.started": "2025-04-20T19:05:09.859729Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupt</th>\n",
       "      <th>hypotheses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Экологическая составляющая ситуации Аральского...</td>\n",
       "      <td>[Экологическая составляющая ситуации Аральског...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Смысл всегда выражается понятно , но термины и...</td>\n",
       "      <td>[Смысл всегда выражается понятно , но термины ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Я продолжаю бродить по музею , и в какой-то мо...</td>\n",
       "      <td>[Я продолжаю бродить по музею , и в какой-то м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Видали , как хорошо это получилась с ипотеками...</td>\n",
       "      <td>[Видали , как хорошо это получилось с ипотекам...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Со стороной этой красивой вещи , я поняла , чт...</td>\n",
       "      <td>[Со стороной этой красивой вещи , я поняла , ч...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             corrupt  \\\n",
       "0  Экологическая составляющая ситуации Аральского...   \n",
       "1  Смысл всегда выражается понятно , но термины и...   \n",
       "2  Я продолжаю бродить по музею , и в какой-то мо...   \n",
       "3  Видали , как хорошо это получилась с ипотеками...   \n",
       "4  Со стороной этой красивой вещи , я поняла , чт...   \n",
       "\n",
       "                                          hypotheses  \n",
       "0  [Экологическая составляющая ситуации Аральског...  \n",
       "1  [Смысл всегда выражается понятно , но термины ...  \n",
       "2  [Я продолжаю бродить по музею , и в какой-то м...  \n",
       "3  [Видали , как хорошо это получилось с ипотекам...  \n",
       "4  [Со стороной этой красивой вещи , я поняла , ч...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(corrupt_corrected_pairs, columns=['corrupt', 'hypotheses'])\n",
    "# df.hypotheses = df.hypotheses.map(lambda x: [x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5243b0-ac55-43ea-b8e4-bbfc30058348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T19:05:27.583702Z",
     "iopub.status.busy": "2025-04-20T19:05:27.583246Z",
     "iopub.status.idle": "2025-04-20T19:05:27.783523Z",
     "shell.execute_reply": "2025-04-20T19:05:27.782282Z",
     "shell.execute_reply.started": "2025-04-20T19:05:27.583681Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('hypotheses_v1_mult.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b5940-dcbf-4890-88ad-55d2123dd80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
